{"version":3,"file":"create_manifest_data.js","sources":["../src/core/create_app.ts","../node_modules/require-relative/index.js","../node_modules/rollup-dependency-tree/dist/index.js","../src/core/create_compilers/extract_css.ts","../src/core/create_compilers/RollupResult.ts","../src/core/create_compilers/RollupCompiler.ts","../node_modules/webpack-format-messages/index.js","../src/core/create_compilers/WebpackResult.ts","../src/core/create_compilers/WebpackCompiler.ts","../src/core/create_compilers/index.ts","../src/core/create_manifest_data.ts"],"sourcesContent":["import * as fs from 'fs';\nimport * as path from 'path';\nimport { posixify, stringify, walk, write_if_changed } from '../utils';\nimport { Page, PageComponent, ManifestData } from '../interfaces';\n\nexport function create_app({\n\tbundler,\n\tmanifest_data,\n\tdev_port,\n\tdev,\n\tcwd,\n\tsrc,\n\tdest,\n\troutes,\n\toutput\n}: {\n\tbundler: string,\n\tmanifest_data: ManifestData;\n\tdev_port?: number;\n\tdev: boolean;\n\tcwd: string;\n\tsrc: string;\n\tdest: string;\n\troutes: string;\n\toutput: string\n}) {\n\tif (!fs.existsSync(output)) fs.mkdirSync(output);\n\n\tconst path_to_routes = path.relative(`${output}/internal`, routes);\n\n\tconst client_manifest = generate_client_manifest(manifest_data, path_to_routes, bundler, dev, dev_port);\n\tconst server_manifest = generate_server_manifest(manifest_data, path_to_routes, cwd, src, dest, dev);\n\n\tconst app = generate_app(manifest_data, path_to_routes);\n\n\twrite_if_changed(`${output}/internal/manifest-client.mjs`, client_manifest);\n\twrite_if_changed(`${output}/internal/manifest-server.mjs`, server_manifest);\n\twrite_if_changed(`${output}/internal/App.svelte`, app);\n}\n\nexport function create_serviceworker_manifest({ manifest_data, output, client_files, static_files }: {\n\tmanifest_data: ManifestData;\n\toutput: string;\n\tclient_files: string[];\n\tstatic_files: string;\n}) {\n\tlet files: string[] = ['service-worker-index.html'];\n\n\tif (fs.existsSync(static_files)) {\n\t\tfiles = files.concat(walk(static_files));\n\t} else {\n\t\t// TODO remove in a future version\n\t\tif (fs.existsSync('assets')) {\n\t\t\tthrow new Error(`As of Sapper 0.21, the assets/ directory should become static/`);\n\t\t}\n\t}\n\n\tlet code = `\n\t\t// This file is generated by Sapper — do not edit it!\n\t\texport const timestamp = ${Date.now()};\n\n\t\texport const files = [\\n\\t${files.map((x: string) => stringify('/' + x)).join(',\\n\\t')}\\n];\n\t\texport { files as assets }; // legacy\n\n\t\texport const shell = [\\n\\t${client_files.map((x: string) => stringify('/' + x)).join(',\\n\\t')}\\n];\n\n\t\texport const routes = [\\n\\t${manifest_data.pages.map((r: Page) => `{ pattern: ${r.pattern} }`).join(',\\n\\t')}\\n];\n\t`.replace(/^\\t\\t/gm, '').trim();\n\n\twrite_if_changed(`${output}/service-worker.js`, code);\n}\n\nfunction create_param_match(param: string, i: number) {\n\treturn /^\\.{3}.+$/.test(param)\n\t\t? `${param.replace(/.{3}/, '')}: d(match[${i + 1}]).split('/')`\n\t\t: `${param}: d(match[${i + 1}])`\n}\n\nfunction generate_client_manifest(\n\tmanifest_data: ManifestData,\n\tpath_to_routes: string,\n\tbundler: string,\n\tdev: boolean,\n\tdev_port?: number\n) {\n\tconst page_ids = new Set(manifest_data.pages.map(page =>\n\t\tpage.pattern.toString()));\n\n\tconst server_routes_to_ignore = manifest_data.server_routes.filter(route =>\n\t\t!page_ids.has(route.pattern.toString()));\n\n\tconst component_indexes: Record<string, number> = {};\n\n\tconst components = `[\n\t\t${manifest_data.components.map((component, i) => {\n\t\t\tconst annotation = bundler === 'webpack'\n\t\t\t\t? `/* webpackChunkName: \"${component.name}\" */ `\n\t\t\t\t: '';\n\n\t\t\tconst source = get_file(path_to_routes, component);\n\n\t\t\tcomponent_indexes[component.name] = i;\n\n\t\t\treturn `{\n\t\t\t\t\tjs: () => import(${annotation}${stringify(source)}),\n\t\t\t\t\tcss: \"__SAPPER_CSS_PLACEHOLDER:${stringify(component.file, false)}__\"\n\t\t\t\t}`;\n\t\t}).join(',\\n\\t\\t\\t\\t')}\n\t]`.replace(/^\\t/gm, '');\n\n\tlet needs_decode = false;\n\n\tlet routes = `[\n\t\t\t\t${manifest_data.pages.map(page => `{\n\t\t\t\t\t// ${page.parts[page.parts.length - 1].component.file}\n\t\t\t\t\tpattern: ${page.pattern},\n\t\t\t\t\tparts: [\n\t\t\t\t\t\t${page.parts.map(part => {\n\t\t\t\t\t\t\tconst missing_layout = !part;\n\t\t\t\t\t\t\tif (missing_layout) return 'null';\n\n\t\t\t\t\t\t\tif (part.params.length > 0) {\n\t\t\t\t\t\t\t\tneeds_decode = true;\n\t\t\t\t\t\t\t\tconst props = part.params.map(create_param_match);\n\t\t\t\t\t\t\t\treturn `{ i: ${component_indexes[part.component.name]}, params: match => ({ ${props.join(', ')} }) }`;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\treturn `{ i: ${component_indexes[part.component.name]} }`;\n\t\t\t\t\t\t}).join(',\\n\\t\\t\\t\\t\\t\\t')}\n\t\t\t\t\t]\n\t\t\t\t}`).join(',\\n\\n\\t\\t\\t\\t')}\n\t]`.replace(/^\\t/gm, '');\n\n\tif (needs_decode) {\n\t\troutes = `(d => ${routes})(decodeURIComponent)`\n\t}\n\n\treturn `\n\t\t// This file is generated by Sapper — do not edit it!\n\t\t// webpack does not support export * as root_comp yet so do a two line import/export\n\t\timport * as root_comp from '${stringify(get_file(path_to_routes, manifest_data.root), false)}';\n\t\texport { root_comp };\n\t\texport { default as ErrorComponent } from '${stringify(get_file(path_to_routes, manifest_data.error), false)}';\n\n\t\texport const ignore = [${server_routes_to_ignore.map(route => route.pattern).join(', ')}];\n\n\t\texport const components = ${components};\n\n\t\texport const routes = ${routes};\n\n\t\t${dev ? `if (typeof window !== 'undefined') {\n\t\t\timport(${stringify(posixify(path.resolve(__dirname, '../sapper-dev-client.js')))}).then(client => {\n\t\t\t\tclient.connect(${dev_port});\n\t\t\t});\n\t\t}` : ''}\n\t`.replace(/^\\t{2}/gm, '').trim();\n}\n\nfunction generate_server_manifest(\n\tmanifest_data: ManifestData,\n\tpath_to_routes: string,\n\tcwd: string,\n\tsrc: string,\n\tdest: string,\n\tdev: boolean\n) {\n\tconst imports = [].concat(\n\t\tmanifest_data.server_routes.map((route, i) =>\n\t\t\t`import * as route_${i} from ${stringify(posixify(`${path_to_routes}/${route.file}`))};`),\n\t\tmanifest_data.components.map((component, i) =>\n\t\t\t`import * as component_${i} from ${stringify(get_file(path_to_routes, component))};`),\n\t\t`import * as root_comp from ${stringify(get_file(path_to_routes, manifest_data.root))};`,\n\t\t`import error from ${stringify(get_file(path_to_routes, manifest_data.error))};`\n\t);\n\n\tconst component_lookup: Record<string, number> = {};\n\tmanifest_data.components.forEach((component, i) => {\n\t\tcomponent_lookup[component.name] = i;\n\t});\n\n\tlet code = `\n\t\t`.replace(/^\\t\\t/gm, '').trim();\n\n\tconst build_dir = posixify(path.normalize(path.relative(cwd, dest)));\n\tconst src_dir = posixify(path.normalize(path.relative(cwd, src)));\n\n\treturn `\n\t\t// This file is generated by Sapper — do not edit it!\n\t\t${imports.join('\\n')}\n\n\t\tconst d = decodeURIComponent;\n\n\t\texport const manifest = {\n\t\t\tserver_routes: [\n\t\t\t\t${manifest_data.server_routes.map((route, i) => `{\n\t\t\t\t\t// ${route.file}\n\t\t\t\t\tpattern: ${route.pattern},\n\t\t\t\t\thandlers: route_${i},\n\t\t\t\t\tparams: ${route.params.length > 0\n\t\t\t\t\t\t? `match => ({ ${route.params.map(create_param_match).join(', ')} })`\n\t\t\t\t\t\t: `() => ({})`}\n\t\t\t\t}`).join(',\\n\\n\\t\\t\\t\\t')}\n\t\t\t],\n\n\t\t\tpages: [\n\t\t\t\t${manifest_data.pages.map(page => `{\n\t\t\t\t\t// ${page.parts[page.parts.length - 1].component.file}\n\t\t\t\t\tpattern: ${page.pattern},\n\t\t\t\t\tparts: [\n\t\t\t\t\t\t${page.parts.map(part => {\n\t\t\t\t\t\t\tif (part === null) return 'null';\n\n\t\t\t\t\t\t\tconst props = [\n\t\t\t\t\t\t\t\t`name: \"${part.component.name}\"`,\n\t\t\t\t\t\t\t\t`file: ${stringify(part.component.file)}`,\n\t\t\t\t\t\t\t\t`component: component_${component_lookup[part.component.name]}`\n\t\t\t\t\t\t\t].filter(Boolean);\n\n\t\t\t\t\t\t\tif (part.params.length > 0) {\n\t\t\t\t\t\t\t\tconst params = part.params.map(create_param_match);\n\t\t\t\t\t\t\t\tprops.push(`params: match => ({ ${params.join(', ')} })`);\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\treturn `{ ${props.join(', ')} }`;\n\t\t\t\t\t\t}).join(',\\n\\t\\t\\t\\t\\t\\t')}\n\t\t\t\t\t]\n\t\t\t\t}`).join(',\\n\\n\\t\\t\\t\\t')}\n\t\t\t],\n\n\t\t\troot_comp,\n\t\t\terror\n\t\t};\n\n\t\texport const build_dir = ${JSON.stringify(build_dir)};\n\n\t\texport const src_dir = ${JSON.stringify(src_dir)};\n\n\t\texport const dev = ${dev ? 'true' : 'false'};\n\t`.replace(/^\\t{2}/gm, '').trim();\n}\n\nfunction generate_app(manifest_data: ManifestData, path_to_routes: string) {\n\t// TODO remove default layout altogether\n\n\tconst max_depth = Math.max(...manifest_data.pages.map(page => page.parts.filter(Boolean).length));\n\n\tconst levels = [];\n\tfor (let i = 0; i < max_depth; i += 1) {\n\t\tlevels.push(i + 1);\n\t}\n\n\tlet l = max_depth;\n\n\tlet pyramid = `<svelte:component this=\"{level${l}.component}\" {...level${l}.props}/>`;\n\n\twhile (l-- > 1) {\n\t\tpyramid = `\n\t\t\t<svelte:component this=\"{level${l}.component}\" segment=\"{segments[${l}]}\" {...level${l}.props}>\n\t\t\t\t{#if level${l + 1}}\n\t\t\t\t\t${pyramid.replace(/\\n/g, '\\n\\t\\t\\t\\t\\t')}\n\t\t\t\t{/if}\n\t\t\t</svelte:component>\n\t\t`.replace(/^\\t\\t\\t/gm, '').trim();\n\t}\n\n\treturn `\n\t\t<!-- This file is generated by Sapper — do not edit it! -->\n\t\t<script>\n\t\t\timport { setContext, afterUpdate } from 'svelte';\n\t\t\timport { CONTEXT_KEY } from './shared';\n\t\t\timport Layout from '${get_file(path_to_routes, manifest_data.root)}';\n\t\t\timport Error from '${get_file(path_to_routes, manifest_data.error)}';\n\n\t\t\texport let stores;\n\t\t\texport let error;\n\t\t\texport let status;\n\t\t\texport let segments;\n\t\t\texport let level0;\n\t\t\t${levels.map(l => `export let level${l} = null;`).join('\\n\\t\\t\\t')}\n\t\t\texport let notify;\n\n\t\t\tafterUpdate(notify);\n\t\t\tsetContext(CONTEXT_KEY, stores);\n\t\t</script>\n\n\t\t<Layout segment=\"{segments[0]}\" {...level0.props}>\n\t\t\t{#if error}\n\t\t\t\t<Error {error} {status}/>\n\t\t\t{:else}\n\t\t\t\t${pyramid.replace(/\\n/g, '\\n\\t\\t\\t\\t')}\n\t\t\t{/if}\n\t\t</Layout>\n\t`.replace(/^\\t\\t/gm, '').trim();\n}\n\nfunction get_file(path_to_routes: string, component: PageComponent) {\n\tif (component.default) return `./${component.type}.svelte`;\n\treturn posixify(`${path_to_routes}/${component.file}`);\n}\n","/*\nrelative require\n*/'use strict';\n\nvar path = require('path');\nvar Module = require('module');\n\nvar modules = {};\n\nvar getModule = function(dir) {\n  var rootPath = dir ? path.resolve(dir) : process.cwd();\n  var rootName = path.join(rootPath, '@root');\n  var root = modules[rootName];\n  if (!root) {\n    root = new Module(rootName);\n    root.filename = rootName;\n    root.paths = Module._nodeModulePaths(rootPath);\n    modules[rootName] = root;\n  }\n  return root;\n};\n\nvar requireRelative = function(requested, relativeTo) {\n  var root = getModule(relativeTo);\n  return root.require(requested);\n};\n\nrequireRelative.resolve = function(requested, relativeTo) {\n  var root = getModule(relativeTo);\n  return Module._resolveFilename(requested, root);\n};\n\nmodule.exports = requireRelative;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction default_1(chunks) {\n    var result = {};\n    chunks.filter(function (chunk) { return chunk.facadeModuleId; })\n        .forEach(function (chunk) { result[chunk.facadeModuleId] = Array.from(getImports(chunks, [chunk])); });\n    return result;\n}\nexports.default = default_1;\n;\nfunction getImports(allChunks, chunksToResolve) {\n    var result = new Set();\n    chunksToResolve.forEach(function (chunk) {\n        chunk.imports.forEach(function (fileName) {\n            if (!result.has(fileName)) { // avoid cycles\n                result.add(fileName);\n                var importedChunks = allChunks.filter(function (chunk) { return chunk.fileName === fileName; });\n                getImports(allChunks, importedChunks).forEach(function (fileName) { return result.add(fileName); });\n            }\n        });\n    });\n    return result;\n}\n","import * as fs from 'fs';\nimport * as path from 'path';\nimport hash from 'string-hash';\nimport * as codec from 'sourcemap-codec';\nimport { PageComponent, Dirs } from '../../interfaces';\nimport { CompileResult, Chunk } from './interfaces';\nimport { normalize_path, posixify } from '../../utils'\n\nconst inline_sourcemap_header = 'data:application/json;charset=utf-8;base64,';\n\nfunction extract_sourcemap(raw: string, id: string) {\n\tlet raw_map: string;\n\tlet map = null;\n\n\tconst code = raw.replace(/\\/\\*#\\s+sourceMappingURL=(.+)\\s+\\*\\//g, (m, url) => {\n\t\tif (raw_map) {\n\t\t\t// TODO should not happen!\n\t\t\tthrow new Error(`Found multiple sourcemaps in single CSS file (${id})`);\n\t\t}\n\n\t\traw_map = url;\n\t\treturn '';\n\t}).trim();\n\n\tif (raw_map) {\n\t\tif (raw_map.startsWith(inline_sourcemap_header)) {\n\t\t\tconst json = Buffer.from(raw_map.slice(inline_sourcemap_header.length), 'base64').toString();\n\t\t\tmap = JSON.parse(json);\n\t\t} else {\n\t\t\t// TODO do we want to handle non-inline sourcemaps? could be a rabbit hole\n\t\t}\n\t}\n\n\treturn {\n\t\tcode,\n\t\tmap\n\t};\n}\n\ntype SourceMap = {\n\tversion: 3;\n\tfile: string;\n\tsources: string[];\n\tsourcesContent: string[];\n\tnames: string[];\n\tmappings: string;\n};\n\nfunction get_css_from_modules(modules: string[], css_map: Map<string, string>, asset_dir: string) {\n\tconst parts: string[] = [];\n\tconst mappings: number[][][] = [];\n\n\tconst combined_map: SourceMap = {\n\t\tversion: 3,\n\t\tfile: null,\n\t\tsources: [],\n\t\tsourcesContent: [],\n\t\tnames: [],\n\t\tmappings: null\n\t};\n\n\tmodules.forEach(module => {\n\t\tif (!/\\.css$/.test(module)) return;\n\n\t\tconst css = css_map.get(module);\n\n\t\tconst { code, map } = extract_sourcemap(css, module);\n\n\t\tparts.push(code);\n\n\t\tif (map) {\n\t\t\tconst lines = codec.decode(map.mappings);\n\n\t\t\tif (combined_map.sources.length > 0 || combined_map.names.length > 0) {\n\t\t\t\tlines.forEach(line => {\n\t\t\t\t\tline.forEach(segment => {\n\t\t\t\t\t\t// adjust source index\n\t\t\t\t\t\tsegment[1] += combined_map.sources.length;\n\n\t\t\t\t\t\t// adjust name index\n\t\t\t\t\t\tif (segment[4]) segment[4] += combined_map.names.length;\n\t\t\t\t\t});\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tcombined_map.sources.push(...map.sources);\n\t\t\tcombined_map.sourcesContent.push(...map.sourcesContent);\n\t\t\tcombined_map.names.push(...map.names);\n\n\t\t\tmappings.push(...lines);\n\t\t}\n\t});\n\n\tif (parts.length > 0) {\n\t\tcombined_map.mappings = codec.encode(mappings);\n\n\t\tcombined_map.sources = combined_map.sources.map(source => path.relative(asset_dir, source).replace(/\\\\/g, '/'));\n\n\t\treturn {\n\t\t\tcode: parts.join('\\n'),\n\t\t\tmap: combined_map\n\t\t};\n\t}\n\n\treturn null;\n}\n\nexport default function extract_css(\n\tclient_result: CompileResult,\n\tcomponents: PageComponent[],\n\tdirs: Dirs,\n\tsourcemap: boolean | 'inline'\n) {\n\tconst result: {\n\t\tmain: string | null;\n\t\tchunks: Record<string, string[]>\n\t} = {\n\t\tmain: null,\n\t\tchunks: {}\n\t};\n\n\tif (!client_result.css_files) return; // Rollup-only for now\n\n\tlet asset_dir = `${dirs.dest}/client`;\n\tif (process.env.SAPPER_LEGACY_BUILD) asset_dir += '/legacy';\n\n\tconst unclaimed = new Set(client_result.css_files.map(x => x.id));\n\n\tconst lookup = new Map();\n\tclient_result.chunks.forEach(chunk => {\n\t\tlookup.set(chunk.file, chunk);\n\t});\n\n\tconst css_map = new Map();\n\tclient_result.css_files.forEach(css_module => {\n\t\tcss_map.set(css_module.id, css_module.code);\n\t});\n\n\tconst chunks_with_css = new Set();\n\n\t// concatenate and emit CSS\n\tclient_result.chunks.forEach(chunk => {\n\t\tconst css_modules = chunk.modules.filter(m => css_map.has(m));\n\t\tif (!css_modules.length) return;\n\n\t\tconst css = get_css_from_modules(css_modules, css_map, asset_dir);\n\n\t\tlet { code, map } = css;\n\n\t\tconst output_file_name = chunk.file.replace(/\\.js$/, '.css');\n\n\t\tmap.file = output_file_name;\n\n\t\tif (sourcemap === true) {\n\t\t\tfs.writeFileSync(`${asset_dir}/${output_file_name}.map`, JSON.stringify(map, null, '  '));\n\t\t\tcode += `\\n/*# sourceMappingURL=${output_file_name}.map */`;\n\t\t}\n\n\t\tif (sourcemap === 'inline') {\n\t\t\tconst base64 = Buffer.from(JSON.stringify(map), 'utf8').toString('base64')\n\t\t\tcode += `\\n/*# sourceMappingURL=${inline_sourcemap_header}${base64} */`;\n\t\t}\n\n\t\tfs.writeFileSync(`${asset_dir}/${output_file_name}`, code);\n\n\t\tchunks_with_css.add(chunk);\n\t});\n\n\tconst entry = path.resolve(dirs.src, 'client.js');\n\tconst entry_chunk = client_result.chunks.find(chunk => chunk.modules.indexOf(entry) !== -1);\n\n\tconst entry_chunk_dependencies: Set<Chunk> = new Set([entry_chunk]);\n\tconst entry_css_modules: string[] = [];\n\n\t// recursively find the chunks this component depends on\n\tentry_chunk_dependencies.forEach(chunk => {\n\t\tif (!chunk) return; // TODO why does this happen?\n\n\t\tchunk.imports.forEach(file => {\n\t\t\tentry_chunk_dependencies.add(lookup.get(file));\n\t\t});\n\n\t\tif (chunks_with_css.has(chunk)) {\n\t\t\tchunk.modules.forEach(file => {\n\t\t\t\tunclaimed.delete(file);\n\t\t\t\tif (css_map.has(file)) {\n\t\t\t\t\tentry_css_modules.push(file);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n\n\t// figure out which (css-having) chunks each component depends on\n\tcomponents.forEach(component => {\n\t\tconst resolved = normalize_path(path.resolve(dirs.routes, component.file));\n\t\tconst chunk: Chunk = client_result.chunks.find(chunk => chunk.modules.indexOf(resolved) !== -1);\n\n\t\tif (!chunk) {\n\t\t\t// this should never happen!\n\t\t\tthrow new Error(`Could not find chunk that owns ${component.file}`);\n\t\t}\n\n\t\tconst chunk_dependencies: Set<Chunk> = new Set([chunk]);\n\t\tconst css_dependencies: string[] = [];\n\n\t\t// recursively find the chunks this component depends on\n\t\tchunk_dependencies.forEach(chunk => {\n\t\t\tif (!chunk) return; // TODO why does this happen?\n\n\t\t\tchunk.imports.forEach(file => {\n\t\t\t\tchunk_dependencies.add(lookup.get(file));\n\t\t\t});\n\n\t\t\tif (chunks_with_css.has(chunk)) {\n\t\t\t\tcss_dependencies.push(chunk.file.replace(/\\.js$/, '.css'));\n\n\t\t\t\tchunk.modules.forEach(file => {\n\t\t\t\t\tunclaimed.delete(file);\n\t\t\t\t});\n\t\t\t}\n\t\t});\n\n\t\tresult.chunks[component.file] = css_dependencies;\n\t});\n\n\tfs.readdirSync(asset_dir).forEach(file => {\n\t\tif (!file.endsWith('.js') || fs.statSync(`${asset_dir}/${file}`).isDirectory()) return;\n\n\t\tconst source = fs.readFileSync(`${asset_dir}/${file}`, 'utf-8');\n\n\t\tconst replaced = source.replace(/(\\\\?[\"'])__SAPPER_CSS_PLACEHOLDER:([^\"']+?)__\\1/g, (m, quotes, route) => {\n\t\t\tlet replacement = JSON.stringify(\n\t\t\t\tprocess.env.SAPPER_LEGACY_BUILD && result.chunks[route] ?\n\t\t\t\t\tresult.chunks[route].map(_ => `legacy/${_}`) :\n\t\t\t\t\tresult.chunks[route]\n\t\t\t);\n\n\t\t\t// If the quotation marks are escaped, then\n\t\t\t// the source code is in a string literal\n\t\t\t// (e.g., source maps) rather than raw\n\t\t\t// JavaScript source. We need to stringify\n\t\t\t// again and then remove the extra quotation\n\t\t\t// marks so that replacement is correct.\n\t\t\tif (quotes[0] === '\\\\') {\n\t\t\t\treplacement = JSON.stringify(replacement);\n\t\t\t\treplacement = replacement.substring(1, replacement.length - 1);\n\t\t\t}\n\n\t\t\treturn replacement;\n\t\t});\n\n\t\tfs.writeFileSync(`${asset_dir}/${file}`, replaced);\n\t});\n\n\tunclaimed.forEach(file => {\n\t\tentry_css_modules.push(file);\n\t});\n\n\tconst leftover = get_css_from_modules(entry_css_modules, css_map, asset_dir);\n\tif (leftover) {\n\t\tlet { code, map } = leftover;\n\n\t\tconst main_hash = hash(code);\n\n\t\tconst output_file_name = `main.${main_hash}.css`;\n\n\t\tmap.file = output_file_name;\n\n\t\tif (sourcemap === true) {\n\t\t\tfs.writeFileSync(`${asset_dir}/${output_file_name}.map`, JSON.stringify(map, null, '  '));\n\t\t\tcode += `\\n/*# sourceMappingURL=client/${output_file_name}.map */`;\n\t\t}\n\n\t\tif (sourcemap === 'inline') {\n\t\t\tconst base64 = Buffer.from(JSON.stringify(map), 'utf8').toString('base64')\n\t\t\tcode += `\\n/*# sourceMappingURL=${inline_sourcemap_header}${base64} */`;\n\t\t}\n\n\t\tfs.writeFileSync(`${asset_dir}/${output_file_name}`, code);\n\n\t\tresult.main = output_file_name;\n\t}\n\n\treturn result;\n}\n","import * as path from 'path';\nimport colors from 'kleur';\nimport pb from 'pretty-bytes';\nimport transitiveDeps from 'rollup-dependency-tree';\nimport RollupCompiler from './RollupCompiler';\nimport extract_css from './extract_css';\nimport { left_pad, normalize_path } from '../../utils';\nimport { CompileResult, BuildInfo, CompileError, Chunk, CssFile } from './interfaces';\nimport { ManifestData, Dirs } from '../../interfaces';\n\nexport default class RollupResult implements CompileResult {\n\tduration: number;\n\terrors: CompileError[];\n\twarnings: CompileError[];\n\tchunks: Chunk[];\n\tassets: Record<string, string>;\n\tdependencies: Record<string, string[]>;\n\tcss_files: CssFile[];\n\tcss: {\n\t\tmain: string,\n\t\tchunks: Record<string, string[]>\n\t};\n\tsourcemap: boolean | 'inline';\n\tsummary: string;\n\n\tconstructor(duration: number, compiler: RollupCompiler, sourcemap: boolean | 'inline') {\n\t\tthis.duration = duration;\n\t\tthis.sourcemap = sourcemap\n\n\t\tthis.errors = compiler.errors.map(munge_warning_or_error);\n\t\tthis.warnings = compiler.warnings.map(munge_warning_or_error);\n\n\t\tthis.chunks = compiler.chunks.map(chunk => ({\n\t\t\tfile: chunk.fileName,\n\t\t\timports: chunk.imports.filter(Boolean),\n\t\t\tmodules: Object.keys(chunk.modules).map(m => normalize_path(m))\n\t\t}));\n\n\t\tthis.css_files = compiler.css_files;\n\n\t\tthis.assets = {};\n\n\t\tif (typeof compiler.input === 'string') {\n\t\t\tcompiler.chunks.forEach(chunk => {\n\t\t\t\tif (compiler.input in chunk.modules) {\n\t\t\t\t\tthis.assets.main = chunk.fileName;\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\tfor (const name in compiler.input) {\n\t\t\t\tconst file = compiler.input[name];\n\t\t\t\tconst chunk = compiler.chunks.find(chunk => file in chunk.modules);\n\t\t\t\tif (chunk) this.assets[name] = chunk.fileName;\n\t\t\t}\n\t\t}\n\n\t\tthis.dependencies = transitiveDeps(compiler.chunks);\n\n\t\tthis.summary = compiler.chunks.map(chunk => {\n\t\t\tconst size_color = chunk.code.length > 150000 ? colors.bold().red : chunk.code.length > 50000 ? colors.bold().yellow : colors.bold().white;\n\t\t\tconst size_label = left_pad(pb(chunk.code.length), 10);\n\n\t\t\tconst lines = [size_color(`${size_label} ${chunk.fileName}`)];\n\n\t\t\tconst deps = Object.keys(chunk.modules)\n\t\t\t\t.map(file => {\n\t\t\t\t\treturn {\n\t\t\t\t\t\tfile: path.relative(process.cwd(), file),\n\t\t\t\t\t\tsize: chunk.modules[file].renderedLength\n\t\t\t\t\t};\n\t\t\t\t})\n\t\t\t\t.filter(dep => dep.size > 0)\n\t\t\t\t.sort((a, b) => b.size - a.size);\n\n\t\t\tconst total_unminified = deps.reduce((t, d) => t + d.size, 0);\n\n\t\t\tdeps.forEach((dep, i) => {\n\t\t\t\tconst c = i === deps.length - 1 ? '└' : '│';\n\t\t\t\tlet line = `           ${c} ${dep.file}`;\n\n\t\t\t\tif (deps.length > 1) {\n\t\t\t\t\tconst p = (100 * dep.size / total_unminified).toFixed(1);\n\t\t\t\t\tline += ` (${p}%)`;\n\t\t\t\t}\n\n\t\t\t\tlines.push(colors.gray(line));\n\t\t\t});\n\n\t\t\treturn lines.join('\\n');\n\t\t}).join('\\n');\n\t}\n\n\tto_json(manifest_data: ManifestData, dirs: Dirs): BuildInfo {\n\t\tconst dependencies = {};\n\t\tObject.entries(this.dependencies).forEach(([key, value]) => {\n\t\t\tdependencies[path.relative(dirs.routes, key)] = value;\n\t\t});\n\n\t\treturn {\n\t\t\tbundler: 'rollup',\n\t\t\tshimport: require('shimport/package.json').version,\n\t\t\tassets: this.assets,\n\t\t\tdependencies,\n\n\t\t\t// TODO extract_css has side-effects that don't belong in a method called to_json\n\t\t\tcss: extract_css(this, manifest_data.components, dirs, this.sourcemap)\n\t\t};\n\t}\n\n\tprint() {\n\t\tconst blocks: string[] = this.warnings.map(warning => {\n\t\t\treturn warning.file\n\t\t\t\t? `> ${colors.bold(warning.file)}\\n${warning.message}`\n\t\t\t\t: `> ${warning.message}`;\n\t\t});\n\n\t\tblocks.push(this.summary);\n\n\t\treturn blocks.join('\\n\\n');\n\t}\n}\n\nfunction munge_warning_or_error(warning_or_error: any) {\n\treturn {\n\t\tfile: warning_or_error.filename,\n\t\tmessage: [warning_or_error.message, warning_or_error.frame].filter(Boolean).join('\\n')\n\t};\n}\n\n","import * as path from 'path';\nimport color from 'kleur';\nimport relative from 'require-relative';\nimport { RollupError } from 'rollup/types';\nimport { CompileResult } from './interfaces';\nimport RollupResult from './RollupResult';\n\nconst stderr = console.error.bind(console);\n\nlet rollup: any;\n\nexport default class RollupCompiler {\n\t_: Promise<any>;\n\t_oninvalid: (filename: string) => void;\n\t_start: number;\n\tinput: string;\n\twarnings: any[];\n\terrors: any[];\n\tchunks: any[];\n\tcss_files: Array<{ id: string, code: string }>;\n\n\tconstructor(config: any) {\n\t\tthis._ = this.get_config(config);\n\t\tthis.input = null;\n\t\tthis.warnings = [];\n\t\tthis.errors = [];\n\t\tthis.chunks = [];\n\t\tthis.css_files = [];\n\t}\n\n\tasync get_config(mod: any) {\n\t\t// TODO this is hacky, and doesn't need to apply to all three compilers\n\t\t(mod.plugins || (mod.plugins = [])).push({\n\t\t\tname: 'sapper-internal',\n\t\t\toptions: (opts: any) => {\n\t\t\t\tthis.input = opts.input;\n\t\t\t},\n\t\t\trenderChunk: (code: string, chunk: any) => {\n\t\t\t\tthis.chunks.push(chunk);\n\t\t\t},\n\t\t\ttransform: (code: string, id: string) => {\n\t\t\t\tif (/\\.css$/.test(id)) {\n\t\t\t\t\tthis.css_files.push({ id, code });\n\t\t\t\t\treturn {code: '', moduleSideEffects: 'no-treeshake'};\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\t\tconst onwarn = mod.onwarn || ((warning: any, handler: (warning: any) => void) => {\n\t\t\thandler(warning);\n\t\t});\n\n\t\tmod.onwarn = (warning: any) => {\n\t\t\tonwarn(warning, (warning: any) => {\n\t\t\t\tthis.warnings.push(warning);\n\t\t\t});\n\t\t};\n\n\t\treturn mod;\n\t}\n\n\toninvalid(cb: (filename: string) => void) {\n\t\tthis._oninvalid = cb;\n\t}\n\n\tasync compile(): Promise<CompileResult> {\n\t\tconst config = await this._;\n\t\tconst sourcemap = config.output.sourcemap;\n\n\t\tconst start = Date.now();\n\n\t\ttry {\n\t\t\tconst bundle = await rollup.rollup(config);\n\t\t\tawait bundle.write(config.output);\n\n\t\t\treturn new RollupResult(Date.now() - start, this, sourcemap);\n\t\t} catch (err) {\n\t\t\t// flush warnings\n\t\t\tstderr(new RollupResult(Date.now() - start, this, sourcemap).print());\n\n\t\t\thandleError(err);\n\t\t}\n\t}\n\n\tasync watch(cb: (err?: Error, stats?: any) => void) {\n\t\tconst config = await this._;\n\t\tconst sourcemap = config.output.sourcemap;\n\n\t\tconst watcher = rollup.watch(config);\n\n\t\twatcher.on('change', (id: string) => {\n\t\t\tthis.chunks = [];\n\t\t\tthis.warnings = [];\n\t\t\tthis.errors = [];\n\t\t\tthis._oninvalid(id);\n\t\t});\n\n\t\twatcher.on('event', (event: any) => {\n\t\t\tswitch (event.code) {\n\t\t\t\tcase 'FATAL':\n\t\t\t\t\t// TODO kill the process?\n\t\t\t\t\tif (event.error.filename) {\n\t\t\t\t\t\t// TODO this is a bit messy. Also, can\n\t\t\t\t\t\t// Rollup emit other kinds of error?\n\t\t\t\t\t\tevent.error.message = [\n\t\t\t\t\t\t\t`Failed to build — error in ${event.error.filename}: ${event.error.message}`,\n\t\t\t\t\t\t\tevent.error.frame\n\t\t\t\t\t\t].filter(Boolean).join('\\n');\n\t\t\t\t\t}\n\n\t\t\t\t\tcb(event.error);\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'ERROR':\n\t\t\t\t\tthis.errors.push(event.error);\n\t\t\t\t\tcb(null, new RollupResult(Date.now() - this._start, this, sourcemap));\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'START':\n\t\t\t\tcase 'END':\n\t\t\t\t\t// TODO is there anything to do with this info?\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'BUNDLE_START':\n\t\t\t\t\tthis._start = Date.now();\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'BUNDLE_END':\n\t\t\t\t\tcb(null, new RollupResult(Date.now() - this._start, this, sourcemap));\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tconsole.log(`Unexpected event ${event.code}`);\n\t\t\t}\n\t\t});\n\t}\n\n\tstatic async load_config(cwd: string) {\n\t\tif (!rollup) rollup = relative('rollup', cwd);\n\n\t\tconst input = path.resolve(cwd, 'rollup.config.js');\n\n\t\tconst bundle = await rollup.rollup({\n\t\t\tinput,\n\t\t\tinlineDynamicImports: true,\n\t\t\texternal: (id: string) => {\n\t\t\t\treturn (id[0] !== '.' && !path.isAbsolute(id)) || id.slice(-5, id.length) === '.json';\n\t\t\t}\n\t\t});\n\n\t\tconst {\n\t\t\toutput: [{ code }]\n\t\t} = await bundle.generate({\n\t\t\texports: 'named',\n\t\t\tformat: 'cjs'\n\t\t});\n\n\t\t// temporarily override require\n\t\tconst defaultLoader = require.extensions['.js'];\n\t\trequire.extensions['.js'] = (module: any, filename: string) => {\n\t\t\tif (filename === input) {\n\t\t\t\tmodule._compile(code, filename);\n\t\t\t} else {\n\t\t\t\tdefaultLoader(module, filename);\n\t\t\t}\n\t\t};\n\n\t\tconst config: any = require(input).default;\n\t\tdelete require.cache[input];\n\n\t\treturn config;\n\t}\n}\n\n\n// copied from https://github.com/rollup/rollup/blob/master/cli/logging.ts\n// and updated so that it will compile here\n\nexport function handleError(err: RollupError, recover = false) {\n\tlet description = err.message || err;\n\tif (err.name) description = `${err.name}: ${description}`;\n\tconst message =\n\t\t(err.plugin\n\t\t\t? `(plugin ${(err).plugin}) ${description}`\n\t\t\t: description) || err;\n\n\tstderr(color.bold().red(`[!] ${color.bold(message.toString())}`));\n\n\tif (err.url) {\n\t\tstderr(color.cyan(err.url));\n\t}\n\n\tif (err.loc) {\n\t\tstderr(`${(err.loc.file || err.id)!} (${err.loc.line}:${err.loc.column})`);\n\t} else if (err.id) {\n\t\tstderr(err.id);\n\t}\n\n\tif (err.frame) {\n\t\tstderr(color.dim(err.frame));\n\t}\n\n\tif (err.stack) {\n\t\tstderr(color.dim(err.stack));\n\t}\n\n\tstderr('');\n\n\tif (!recover) process.exit(1);\n}\n","/**\n * This has been adapted from `create-react-app`, authored by Facebook, Inc.\n * see: https://github.com/facebookincubator/create-react-app/tree/master/packages/react-dev-utils\n */\n\nconst colors = require('kleur');\n\nconst errorLabel = 'Syntax error:';\nconst isLikelyASyntaxError = str => str.includes(errorLabel);\n\nconst exportRegex = /\\s*(.+?)\\s*(\")?export '(.+?)' was not found in '(.+?)'/;\nconst stackRegex = /^\\s*at\\s((?!webpack:).)*:\\d+:\\d+[\\s\\)]*(\\n|$)/gm;\n\nfunction formatMessage(message, isError) {\n  let lines = message.split('\\n');\n\n  if (lines.length > 2 && lines[1] === '') {\n    lines.splice(1, 1); // Remove extra newline.\n  }\n\n  // Remove loader notation from filenames:\n  //   `./~/css-loader!./src/App.css` ~~> `./src/App.css`\n  if (lines[0].lastIndexOf('!') !== -1) {\n    lines[0] = lines[0].substr(lines[0].lastIndexOf('!') + 1);\n  }\n\n\t// Remove useless `entry` filename stack details\n  lines = lines.filter(line => line.indexOf(' @ ') !== 0);\n\n  // 0 ~> filename; 1 ~> main err msg\n  if (!lines[0] || !lines[1]) {\n    return lines.join('\\n');\n  }\n\n  // Cleans up verbose \"module not found\" messages for files and packages.\n  if (lines[1].startsWith('Module not found: ')) {\n    lines = [\n      lines[0],\n      lines[1] // \"Module not found: \" is enough detail\n        .replace(\"Cannot resolve 'file' or 'directory' \", '')\n        .replace('Cannot resolve module ', '')\n        .replace('Error: ', '')\n        .replace('[CaseSensitivePathsPlugin] ', '')\n    ];\n  }\n\n  // Cleans up syntax error messages.\n  if (lines[1].startsWith('Module build failed: ')) {\n    lines[1] = lines[1].replace('Module build failed: SyntaxError:', errorLabel);\n  }\n\n  if (lines[1].match(exportRegex)) {\n    lines[1] = lines[1].replace(exportRegex, \"$1 '$4' does not contain an export named '$3'.\");\n  }\n\n  lines[0] = colors.inverse(lines[0]);\n\n  // Reassemble & Strip internal tracing, except `webpack:` -- (create-react-app/pull/1050)\n  return lines.join('\\n').replace(stackRegex, '').trim();\n}\n\nmodule.exports = function (stats) {\n\tconst json = stats.toJson({}, true);\n\n\tconst result = {\n\t\terrors: json.errors.map(msg => formatMessage(msg, true)),\n\t\twarnings: json.warnings.map(msg => formatMessage(msg, false))\n\t};\n\n\t// Only show syntax errors if we have them\n  if (result.errors.some(isLikelyASyntaxError)) {\n    result.errors = result.errors.filter(isLikelyASyntaxError);\n  }\n\n  // First error is usually it; others usually the same\n  if (result.errors.length > 1) {\n    result.errors.length = 1;\n  }\n\n  return result;\n};\n\nmodule.exports.formatMessage = formatMessage;\n","import format_messages from 'webpack-format-messages';\nimport { CompileResult, BuildInfo, CompileError, Chunk, CssFile } from './interfaces';\nimport { ManifestData, Dirs, PageComponent } from '../../interfaces';\n\nconst locPattern = /\\((\\d+):(\\d+)\\)$/;\n\nfunction munge_warning_or_error(message: string) {\n\t// TODO this is all a bit rube goldberg...\n\tconst lines = message.split('\\n');\n\n\tconst file = lines.shift()\n\t\t.replace('\u001b[7m', '') // careful — there is a special character at the beginning of this string\n\t\t.replace('\u001b[27m', '')\n\t\t.replace('./', '');\n\n\tlet line = null;\n\tlet column = null;\n\n\tconst match = locPattern.exec(lines[0]);\n\tif (match) {\n\t\tlines[0] = lines[0].replace(locPattern, '');\n\t\tline = +match[1];\n\t\tcolumn = +match[2];\n\t}\n\n\treturn {\n\t\tfile,\n\t\tmessage: lines.join('\\n')\n\t};\n}\n\nexport default class WebpackResult implements CompileResult {\n\tduration: number;\n\terrors: CompileError[];\n\twarnings: CompileError[];\n\tchunks: Chunk[];\n\tassets: Record<string, string>;\n\tcss_files: CssFile[];\n\tstats: any;\n\n\tconstructor(stats: any) {\n\t\tthis.stats = stats;\n\n\t\tconst info = stats.toJson();\n\n\t\tconst messages = format_messages(stats);\n\n\t\tthis.errors = messages.errors.map(munge_warning_or_error);\n\t\tthis.warnings = messages.warnings.map(munge_warning_or_error);\n\n\t\tthis.duration = info.time;\n\n\t\tthis.chunks = info.assets.map((chunk: { name: string }) => ({ file: chunk.name }));\n\t\tthis.assets = info.assetsByChunkName;\n\t}\n\n\tto_json(manifest_data: ManifestData, dirs: Dirs): BuildInfo {\n\t\tconst extract_css = (assets: string[] | string) => {\n\t\t\tassets = Array.isArray(assets) ? assets : [assets];\n\t\t\treturn assets.find(asset => /\\.css$/.test(asset));\n\t\t};\n\n\t\treturn {\n\t\t\tbundler: 'webpack',\n\t\t\tshimport: null, // webpack has its own loader\n\t\t\tassets: this.assets,\n\t\t\tcss: {\n\t\t\t\tmain: extract_css(this.assets.main),\n\t\t\t\tchunks: manifest_data.components\n\t\t\t\t\t.reduce((chunks: Record<string, string[]>, component: PageComponent) => {\n\t\t\t\t\t\tconst css_dependencies = [];\n\t\t\t\t\t\tconst css = extract_css(this.assets[component.name]);\n\n\t\t\t\t\t\tif (css) css_dependencies.push(css);\n\n\t\t\t\t\t\tchunks[component.file] = css_dependencies;\n\n\t\t\t\t\t\treturn chunks;\n\t\t\t\t\t}, {})\n\t\t\t}\n\t\t};\n\t}\n\n\tprint() {\n\t\treturn this.stats.toString({ colors: true });\n\t}\n}\n","import relative from 'require-relative';\nimport { CompileResult } from './interfaces';\nimport WebpackResult from './WebpackResult';\n\nlet webpack: any;\n\nexport class WebpackCompiler {\n\t_: any;\n\n\tconstructor(config: any) {\n\t\tif (!webpack) webpack = relative('webpack', process.cwd());\n\t\tthis._ = webpack(config);\n\t}\n\n\toninvalid(cb: (filename: string) => void) {\n\t\tthis._.hooks.invalid.tap('sapper', cb);\n\t}\n\n\tcompile(): Promise<CompileResult> {\n\t\treturn new Promise((fulfil, reject) => {\n\t\t\tthis._.run((err: Error, stats: any) => {\n\t\t\t\tif (err) {\n\t\t\t\t\treject(err);\n\t\t\t\t\tprocess.exit(1);\n\t\t\t\t}\n\n\t\t\t\tconst result = new WebpackResult(stats);\n\n\t\t\t\tif (result.errors.length) {\n\t\t\t\t\tconsole.error(stats.toString({ colors: true }));\n\t\t\t\t\treject(new Error(`Encountered errors while building app`));\n\t\t\t\t}\n\n\t\t\t\telse {\n\t\t\t\t\tfulfil(result);\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\t}\n\n\twatch(cb: (err?: Error, stats?: any) => void) {\n\t\tthis._.watch({}, (err?: Error, stats?: any) => {\n\t\t\tcb(err, stats && new WebpackResult(stats));\n\t\t});\n\t}\n}","import * as path from 'path';\nimport RollupCompiler from './RollupCompiler';\nimport { WebpackCompiler } from './WebpackCompiler';\nimport { set_dev, set_src, set_dest } from '../../config/env';\n\nexport type Compiler = RollupCompiler | WebpackCompiler;\n\nexport type Compilers = {\n\tclient: Compiler;\n\tserver: Compiler;\n\tserviceworker?: Compiler;\n}\n\nexport default async function create_compilers(\n\tbundler: 'rollup' | 'webpack',\n\tcwd: string,\n\tsrc: string,\n\tdest: string,\n\tdev: boolean\n): Promise<Compilers> {\n\tset_dev(dev);\n\tset_src(src);\n\tset_dest(dest);\n\n\tif (bundler === 'rollup') {\n\t\tconst config = await RollupCompiler.load_config(cwd);\n\t\tvalidate_config(config, 'rollup');\n\n\t\tnormalize_rollup_config(config.client);\n\t\tnormalize_rollup_config(config.server);\n\n\t\tif (config.serviceworker) {\n\t\t\tnormalize_rollup_config(config.serviceworker);\n\t\t}\n\n\t\treturn {\n\t\t\tclient: new RollupCompiler(config.client),\n\t\t\tserver: new RollupCompiler(config.server),\n\t\t\tserviceworker: config.serviceworker && new RollupCompiler(config.serviceworker)\n\t\t};\n\t}\n\n\tif (bundler === 'webpack') {\n\t\tconst config = require(path.resolve(cwd, 'webpack.config.js'));\n\t\tvalidate_config(config, 'webpack');\n\n\t\treturn {\n\t\t\tclient: new WebpackCompiler(config.client),\n\t\t\tserver: new WebpackCompiler(config.server),\n\t\t\tserviceworker: config.serviceworker && new WebpackCompiler(config.serviceworker)\n\t\t};\n\t}\n\n\t// this shouldn't be possible...\n\tthrow new Error(`Invalid bundler option '${bundler}'`);\n}\n\nfunction validate_config(config: any, bundler: 'rollup' | 'webpack') {\n\tif (!config.client || !config.server) {\n\t\tthrow new Error(`${bundler}.config.js must export a { client, server, serviceworker? } object`);\n\t}\n}\n\nfunction normalize_rollup_config(config: any) {\n\tif (typeof config.input === 'string') {\n\t\tconfig.input = path.normalize(config.input);\n\t} else {\n\t\tfor (const name in config.input) {\n\t\t\tconfig.input[name] = path.normalize(config.input[name]);\n\t\t}\n\t}\n}\n","import * as fs from 'fs';\nimport * as path from 'path';\nimport { Page, PageComponent, ServerRoute, ManifestData } from '../interfaces';\nimport { posixify, reserved_words } from '../utils';\n\nexport default function create_manifest_data(cwd: string, extensions: string = '.svelte .html'): ManifestData {\n\n\tconst component_extensions = extensions.split(' ');\n\n\t// TODO remove in a future version\n\tif (!fs.existsSync(cwd)) {\n\t\tthrow new Error(`As of Sapper 0.21, the routes/ directory should become src/routes/`);\n\t}\n\n\tfunction find_layout(file_name: string, component_name: string, dir: string = '') {\n\t\tconst ext = component_extensions.find((ext) => fs.existsSync(path.join(cwd, dir, `${file_name}${ext}`)));\n\t\tconst file = posixify(path.join(dir, `${file_name}${ext}`))\n\n\t\treturn ext\n\t\t\t? {\n\t\t\t\tname: component_name,\n\t\t\t\tfile: file\n\t\t\t}\n\t\t\t: null;\n\t}\n\n\tconst components: PageComponent[] = [];\n\tconst pages: Page[] = [];\n\tconst server_routes: ServerRoute[] = [];\n\n\tconst default_layout: PageComponent = {\n\t\tdefault: true,\n\t\ttype: 'layout',\n\t\tname: '_default_layout',\n\t\tfile: null\n\t};\n\n\tconst default_error: PageComponent = {\n\t\tdefault: true,\n\t\ttype: 'error',\n\t\tname: '_default_error',\n\t\tfile: null\n\t};\n\n\tfunction walk(\n\t\tdir: string,\n\t\tparent_segments: Part[][],\n\t\tparent_params: string[],\n\t\tstack: Array<{\n\t\t\tcomponent: PageComponent,\n\t\t\tparams: string[]\n\t\t}>\n\t) {\n\t\tconst items = fs.readdirSync(dir)\n\t\t\t.map(basename => {\n\t\t\t\tconst resolved = path.join(dir, basename);\n\t\t\t\tconst file = path.relative(cwd, resolved);\n\t\t\t\tconst is_dir = fs.statSync(resolved).isDirectory();\n\n\t\t\t\tconst ext = path.extname(basename);\n\n\t\t\t\tif (basename[0] === '_') return null;\n\t\t\t\tif (basename[0] === '.' && basename !== '.well-known') return null;\n\t\t\t\tif (!is_dir && !/^\\.[a-z]+$/i.test(ext)) return null; // filter out tmp files etc\n\n\t\t\t\tconst segment = is_dir\n\t\t\t\t\t? basename\n\t\t\t\t\t: basename.slice(0, -ext.length);\n\n\t\t\t\tif (/\\]\\[/.test(segment)) {\n\t\t\t\t\tthrow new Error(`Invalid route ${file} — parameters must be separated`);\n\t\t\t\t}\n\n\t\t\t\tconst parts = get_parts(segment);\n\t\t\t\tconst is_index = is_dir ? false : basename.startsWith('index.');\n\t\t\t\tconst is_page = component_extensions.indexOf(ext) !== -1;\n\t\t\t\tconst route_suffix = basename.slice(basename.indexOf('.'), -ext.length);\n\n\t\t\t\tparts.forEach(part => {\n\t\t\t\t\tif (part.qualifier && /[\\(\\)\\?\\:]/.test(part.qualifier.slice(1, -1))) {\n\t\t\t\t\t\tthrow new Error(`Invalid route ${file} — cannot use (, ), ? or : in route qualifiers`);\n\t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\treturn {\n\t\t\t\t\tbasename,\n\t\t\t\t\text,\n\t\t\t\t\tparts,\n\t\t\t\t\tfile: posixify(file),\n\t\t\t\t\tis_dir,\n\t\t\t\t\tis_index,\n\t\t\t\t\tis_page,\n\t\t\t\t\troute_suffix\n\t\t\t\t};\n\t\t\t})\n\t\t\t.filter(Boolean)\n\t\t\t.sort(comparator);\n\n\t\titems.forEach(item => {\n\t\t\tconst segments = parent_segments.slice();\n\n\t\t\tif (item.is_index) {\n\t\t\t\tif (item.route_suffix) {\n\t\t\t\t\tif (segments.length > 0) {\n\t\t\t\t\t\tconst last_segment = segments[segments.length - 1].slice();\n\t\t\t\t\t\tconst last_part = last_segment[last_segment.length - 1];\n\n\t\t\t\t\t\tif (last_part.dynamic) {\n\t\t\t\t\t\t\tlast_segment.push({ dynamic: false, content: item.route_suffix });\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlast_segment[last_segment.length - 1] = {\n\t\t\t\t\t\t\t\tdynamic: false,\n\t\t\t\t\t\t\t\tcontent: `${last_part.content}${item.route_suffix}`\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tsegments[segments.length - 1] = last_segment;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsegments.push(item.parts);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tsegments.push(item.parts);\n\t\t\t}\n\n\t\t\tconst params = parent_params.slice();\n\t\t\tparams.push(...item.parts.filter(p => p.dynamic).map(p => p.content));\n\n\t\t\tif (item.is_dir) {\n\t\t\t\tconst component = find_layout('_layout', `${get_slug(item.file)}__layout`, item.file);\n\n\t\t\t\tif (component) components.push(component);\n\n\t\t\t\twalk(\n\t\t\t\t\tpath.join(dir, item.basename),\n\t\t\t\t\tsegments,\n\t\t\t\t\tparams,\n\t\t\t\t\tcomponent\n\t\t\t\t\t\t? stack.concat({ component, params })\n\t\t\t\t\t\t: stack.concat(null)\n\t\t\t\t);\n\t\t\t}\n\n\t\t\telse if (item.is_page) {\n\t\t\t\tconst component = {\n\t\t\t\t\tname: get_slug(item.file),\n\t\t\t\t\tfile: item.file\n\t\t\t\t};\n\n\t\t\t\tcomponents.push(component);\n\n\t\t\t\tconst parts = (item.is_index && stack[stack.length - 1] === null)\n\t\t\t\t\t? stack.slice(0, -1).concat({ component, params })\n\t\t\t\t\t: stack.concat({ component, params })\n\n\t\t\t\tpages.push({\n\t\t\t\t\tpattern: get_pattern(segments, true),\n\t\t\t\t\tparts\n\t\t\t\t});\n\t\t\t}\n\n\t\t\telse {\n\t\t\t\tserver_routes.push({\n\t\t\t\t\tname: `route_${get_slug(item.file)}`,\n\t\t\t\t\tpattern: get_pattern(segments, !item.route_suffix),\n\t\t\t\t\tfile: item.file,\n\t\t\t\t\tparams: params\n\t\t\t\t});\n\t\t\t}\n\t\t});\n\t}\n\n\tconst root = find_layout('_layout', 'main') || default_layout;\n\tconst error = find_layout('_error', 'error') || default_error;\n\n\twalk(cwd, [], [], []);\n\n\t// check for clashes\n\tconst seen_pages: Map<string, Page> = new Map();\n\tpages.forEach(page => {\n\t\tconst pattern = page.pattern.toString();\n\t\tif (seen_pages.has(pattern)) {\n\t\t\tconst file = page.parts.pop().component.file;\n\t\t\tconst other_page = seen_pages.get(pattern);\n\t\t\tconst other_file = other_page.parts.pop().component.file;\n\n\t\t\tthrow new Error(`The ${other_file} and ${file} pages clash`);\n\t\t}\n\n\t\tseen_pages.set(pattern, page);\n\t});\n\n\tconst seen_routes: Map<string, ServerRoute> = new Map();\n\tserver_routes.forEach(route => {\n\t\tconst pattern = route.pattern.toString();\n\t\tif (seen_routes.has(pattern)) {\n\t\t\tconst other_route = seen_routes.get(pattern);\n\t\t\tthrow new Error(`The ${other_route.file} and ${route.file} routes clash`);\n\t\t}\n\n\t\tseen_routes.set(pattern, route);\n\t});\n\n\treturn {\n\t\troot,\n\t\terror,\n\t\tcomponents,\n\t\tpages,\n\t\tserver_routes\n\t};\n}\n\ntype Part = {\n\tcontent: string;\n\tdynamic: boolean;\n\tqualifier?: string;\n\tspread?: boolean;\n};\n\nfunction is_spread(path: string) {\n\tconst spread_pattern = /\\[\\.{3}/g;\n\treturn spread_pattern.test(path)\n}\n\nfunction comparator(\n\ta: { basename: string, parts: Part[], file: string, is_index: boolean },\n\tb: { basename: string, parts: Part[], file: string, is_index: boolean }\n) {\n\tif (a.is_index !== b.is_index) {\n\t\tif (a.is_index) return is_spread(a.file) ? 1 : -1;\n\n\t\treturn is_spread(b.file) ? -1 : 1;\n\t}\n\n\tconst max = Math.max(a.parts.length, b.parts.length);\n\n\tfor (let i = 0; i < max; i += 1) {\n\t\tconst a_sub_part = a.parts[i];\n\t\tconst b_sub_part = b.parts[i];\n\n\t\tif (!a_sub_part) return 1; // b is more specific, so goes first\n\t\tif (!b_sub_part) return -1;\n\n\t\t// if spread && index, order later\n\t\tif (a_sub_part.spread && b_sub_part.spread) {\n\t\t\treturn a.is_index ? 1 : -1\n\t\t}\n\n\t\t// If one is ...spread order it later\n\t\tif (a_sub_part.spread !== b_sub_part.spread) return a_sub_part.spread ? 1 : -1;\n\n\t\tif (a_sub_part.dynamic !== b_sub_part.dynamic) {\n\t\t\treturn a_sub_part.dynamic ? 1 : -1;\n\t\t}\n\n\t\tif (!a_sub_part.dynamic && a_sub_part.content !== b_sub_part.content) {\n\t\t\treturn (\n\t\t\t\t(b_sub_part.content.length - a_sub_part.content.length) ||\n\t\t\t\t(a_sub_part.content < b_sub_part.content ? -1 : 1)\n\t\t\t);\n\t\t}\n\n\t\t// If both parts dynamic, check for regexp patterns\n\t\tif (a_sub_part.dynamic && b_sub_part.dynamic) {\n\t\t\tconst regexp_pattern = /\\((.*?)\\)/;\n\t\t\tconst a_match = regexp_pattern.exec(a_sub_part.content);\n\t\t\tconst b_match = regexp_pattern.exec(b_sub_part.content);\n\n\t\t\tif (!a_match && b_match) {\n\t\t\t\treturn 1; // No regexp, so less specific than b\n\t\t\t}\n\t\t\tif (!b_match && a_match) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tif (a_match && b_match && a_match[1] !== b_match[1]) {\n\t\t\t\treturn b_match[1].length - a_match[1].length;\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunction get_parts(part: string): Part[] {\n\treturn part.split(/\\[(.+?\\(.+?\\)|.+?)\\]/)\n\t\t.map((str, i) => {\n\t\t\tif (!str) return null;\n\t\t\tconst dynamic = i % 2 === 1;\n\n\t\t\tconst [, content, qualifier] = dynamic\n\t\t\t\t? /([^(]+)(\\(.+\\))?$/.exec(str)\n\t\t\t\t: [, str, null];\n\n\t\t\treturn {\n\t\t\t\tcontent,\n\t\t\t\tdynamic,\n\t\t\t\tspread: /^\\.{3}.+$/.test(content),\n\t\t\t\tqualifier\n\t\t\t};\n\t\t})\n\t\t.filter(Boolean);\n}\n\nfunction get_slug(file: string) {\n\tlet name = file\n\t\t.replace(/[\\\\\\/]index/, '')\n\t\t.replace(/[\\/\\\\]/g, '_')\n\t\t.replace(/\\.\\w+$/, '')\n\t\t.replace(/\\[([^(]+)(?:\\([^(]+\\))?\\]/, '$$$1')\n\t\t.replace(/[^a-zA-Z0-9_$]/g, c => {\n\t\t\treturn c === '.' ? '_' : `$${c.charCodeAt(0)}`\n\t\t});\n\n\tif (reserved_words.has(name)) name += '_';\n\treturn name;\n}\n\nfunction get_pattern(segments: Part[][], add_trailing_slash: boolean) {\n\tconst path = segments.map(segment => {\n\t\treturn segment.map(part => {\n\t\t\treturn part.dynamic\n\t\t\t\t? part.qualifier || (part.spread ? '(.+)' : '([^\\\\/]+?)')\n\t\t\t\t: encodeURI(part.content.normalize())\n\t\t\t\t\t.replace(/\\?/g, '%3F')\n\t\t\t\t\t.replace(/#/g, '%23')\n\t\t\t\t\t.replace(/%5B/g, '[')\n\t\t\t\t\t.replace(/%5D/g, ']')\n\t\t\t\t\t.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n\t\t}).join('');\n\t}).join('\\\\/');\n\n\tconst trailing = add_trailing_slash && segments.length ? '\\\\/?$' : '$';\n\n\treturn new RegExp(`^\\\\/${path}${trailing}`);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACnSA;;AAEA;;;;;;;;;;;;;AAaA;;;;;AAKA;;;;;AAKA;;;;;;;;;;;;;;;;;;;;;AC/BA;AACA;;;;;;AAMA;AAEA;;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACxHA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;ACjNA;;;;;AAKA;;AAEA;AACA;;AAEA;AACA;;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgDA;;;;;;;;;;;;;;;;;;;;;AAqBA;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AClFA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;"}